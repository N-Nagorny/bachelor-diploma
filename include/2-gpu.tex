\section{Неспециализированные вычисления на графических процессорах}

Прообразом первых графических процессоров, появившихся в 90-е годы
\rom{20} века, были специализированные чипы аркадных автоматов~\cite{enwiki:gpu}. Их использование было обусловлено малыми объёмами оперативной памяти, что не позволяло хранить в ней кадры перед отправкой на устройство видеовывода. В
дальнейшем разделение вычислений на графические и неграфические лишь
усугубилось, что оказало существенное влияние на архитектуру современных
компьютеров.

В начале \rom{21} века графические процессоры получили поддержку шейдеров и возможность работы с числами с плавающей запятой. Это событие поло-
жило начало ряду экспериментов с организацией неграфических параллельных
расчётов на графических процессорах. При помощи графических API данные
передавались в виде текстур, а расчётные программы --- в виде шейдеров~\cite{Berillo}.
Таким образом учёные начали производить вычисления, связанные с матрицами и векторами, на ГПУ. Первой программой, выполнившейся заметно быстрее
на ГПУ, чем на ЦПУ, стала реализация LU-разложения (2005)~\cite{LU-GPU}.

С увеличением популярности использования ГПУ для научных расчётов
начали формироваться идеи фреймворков общего назначения, позволяющих
отойти от графической парадигмы работы с данными и отказаться от использования OpenGL или DirectX. Такими фреймворками впоследствии стали технологии NVIDIA CUDA и OpenCL.

\subsection{Краткий обзор технологии NVIDIA CUDA}

Первоначальная версия NVIDIA CUDA SDK была представлена 15 февраля 2007 г.
В основе CUDA API лежит диалект языка C++~\cite{enwiki:CUDA}.

Компиляция CUDA-программ выполняется специализированным компилятором nvcc. При этом код программ разделяется на host-часть, выполняющуюся ЦПУ, и device-часть, выполняющуюся графическим процессором. В результате получаются как минимум два объектных файла, готовых к сборке в
конечный исполняемый файл в любой среде программирования~\cite{CUDAToolkitDocumentation}.

По сравнению с использовавшимся ранее подходом к организации вычислений общего назначения посредством возможностей графических API, архитектура CUDA имеет ряд преимуществ:
\begin{itemize}
\item использование диалекта языка C++, что позволяет упростить процесс изучения архитектуры;
\item  полная аппаратная поддержка целочисленных и побитовых операций;
\item  разделяемая между потоками память размером в 16 Кбайт может быть
использована под организованный пользователем кэш с более широкой полосой пропускания, чем при выборке из обычных текстур.
\end{itemize}

\subsection{Краткий обзор технологии OpenCL}

OpenCL --- фреймворк для написания компьютерных программ, связанных
с параллельными вычислениями на различных графических и центральных
процессорах, а также ППВМ. В OpenCL входят язык программирования, который базируется на стандарте C99, и интерфейс программирования приложений~\cite{ruwiki:OpenCL}.

Основной задачей проекта OpenCL является создание и поддержка открытого стандарта, позволяющего создавать универсальные программы для параллельных вычислений на различных процессорах и вычислительные машины,
использующие несколько процессоров различных архитектур одновременно.

\subsection{Иерархия потоков выполнения в NVIDIA CUDA}

Как упоминалось ранее, одной из особенностей написания программ с использованием технологии CUDA является разделение всего программного кода
на host- и device-части. Для этого используются спецификаторы функций:
\begin{itemize}
\item \texttt{\_\_host\_\_} --- означает, что данный код предназначен для центрального процессора (используется по умолчанию );
\item \texttt{\_\_device\_\_} --- означает, что данный код работает на видеокарте;
\item \texttt{\_\_global\_\_} --- особый спецификатор для так называемых функций-ядер (kernel), которые запускаются с центрального процессора, а работают на видеокарте.
\end{itemize}

Остановимся подробнее на функциях-ядрах. Их отличие от обычных
функций языка C++ заключается в том, что при вызове они выполняются N раз
параллельно в N потоках выполнения. При этом количество потоков выполнения, которые можно создать на ГПУ, практически не ограничено.

Для организации работы со столь большим количеством потоков используется иерархическая структура: потоки объединяются в варпы (warp), варпы, в
свою очередь, --- в блоки (block), а блоки составляют сетку (grid).

Варп --- это минимальная независимая от других единица выполнения кода. Размер варпа всегда равен 32 потокам. Эти потоки всегда выполняются физически синхронно. Блок --- это автономная группа потоков. Взаимодействия
потоков между блоками невозможны.

Вызов функции-ядра осуществляется следующим образом:
\begin{verbatim}
kernel_name<<<grid_size, block_size>>>(arguments);
\end{verbatim}

В тройных угловых скобках в участке программного кода выше указываются размеры сетки и блока.